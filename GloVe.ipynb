{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GloVe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/callee2006/MachineLearning/blob/master/GloVe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw42L3S_bSqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "#lamda expression, definition of lamda, parameter = l\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "random.seed(1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQcgtkefgVt1",
        "colab_type": "code",
        "outputId": "c55be4cc-e22a-49a2-edca-3ce11b2f0745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qUF3R4acHUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FloatTensor = torch.FloatTensor\n",
        "LongTensor = torch.LongTensor\n",
        "ByteTensor = torch.ByteTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYrZeL0ycTFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getBatch(batch_size, train_data):\n",
        "    random.shuffle(train_data)\n",
        "    sindex = 0\n",
        "    eindex = batch_size\n",
        "    while eindex < len(train_data):\n",
        "        batch = train_data[sindex:eindex]\n",
        "        temp = eindex\n",
        "        eindex = eindex + batch_size\n",
        "        sindex = temp\n",
        "        yield batch\n",
        "    \n",
        "    if eindex >= len(train_data):\n",
        "        batch = train_data[sindex:]\n",
        "        yield batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bwILUq1cUAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequence(seq, word2index):\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return Variable(LongTensor(idxs))\n",
        "\n",
        "def prepare_word(word, word2index):\n",
        "    return Variable(LongTensor([word2index[word]]) if word2index.get(word) is not None else LongTensor([word2index[\"<UNK>\"]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofQkouNLcWkR",
        "colab_type": "text"
      },
      "source": [
        "# **Data load and Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_ZeSgWhcY0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = list(nltk.corpus.gutenberg.sents('melville-moby_dick.txt'))[:500]\n",
        "corpus = [[word.lower() for word in sent] for sent in corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU-M4zFIcqX5",
        "colab_type": "text"
      },
      "source": [
        "**Build vocab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7v0OHeHcwHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = list(set(flatten(corpus)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWgAjQNAczKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2index = {}\n",
        "for vo in vocab:\n",
        "    if word2index.get(vo) is None:\n",
        "        word2index[vo] = len(word2index)\n",
        "        \n",
        "index2word={v:k for k, v in word2index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1XT0wM3iggR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WINDOW_SIZE = 5\n",
        "windows =  flatten([list(nltk.ngrams(['<DUMMY>'] * WINDOW_SIZE + c + ['<DUMMY>'] * WINDOW_SIZE, WINDOW_SIZE * 2 + 1)) for c in corpus])\n",
        "\n",
        "window_data = []\n",
        "\n",
        "for window in windows:\n",
        "    for i in range(WINDOW_SIZE * 2 + 1):\n",
        "        if i == WINDOW_SIZE or window[i] == '<DUMMY>':                      \n",
        "            continue                                                           \n",
        "        window_data.append((window[WINDOW_SIZE], window[i]))                    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3OKmleWc9Mv",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**Weighting Function**\n",
        "\n",
        "Function to prevent X-ij from splashing above a certain value\n",
        "\n",
        "\n",
        "![대체 텍스트](https://github.com/DSKSD/DeepNLP-models-Pytorch/raw/7fec64d72615933e8f4ea499c2dbaa42508f4017/images/03.glove-weighting-function.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIR9J6RVdOCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weighting(w_i, w_j):\n",
        "    try:\n",
        "        x_ij = X_ik[(w_i, w_j)]\n",
        "    except:\n",
        "        x_ij = 1\n",
        "        \n",
        "    x_max = 100 #100 # fixed in paper\n",
        "    alpha = 0.75\n",
        "    \n",
        "    if x_ij < x_max:\n",
        "        result = (x_ij/x_max)**alpha\n",
        "    else:\n",
        "        result = 1\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7UpGTpqdQWq",
        "colab_type": "text"
      },
      "source": [
        "# **Build Co-occurence Matrix X**\n",
        "\n",
        "Because of model complexity, It is important to determine whether a tighter bound can be placed on the number of nonzero elements of X."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTSJO-ordgD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_i = Counter(flatten(corpus)) # X_i, dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_9ZaOmXdhb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ik_window_5 = Counter(window_data) # Co-occurece in window size 5, dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOUivMbQdite",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ik = {}\n",
        "weighting_dic = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xcTe97Jdw2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import combinations_with_replacement\n",
        "# combinations_with_replacement('ABCD', 2)\n",
        "# AA AB AC AD BB BC BD CC CD DD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy4xGsEldxiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for bigram in combinations_with_replacement(vocab, 2):           # bigram : tuple\n",
        "    if X_ik_window_5.get(bigram) is not None: # nonzero elements\n",
        "        co_occer = X_ik_window_5[bigram]\n",
        "        X_ik[bigram] = co_occer + 1                             # log(Xik) -> log(Xik+1) to prevent divergence\n",
        "        X_ik[(bigram[1],bigram[0])] = co_occer+1                # to satisfy X_ik = X_ki\n",
        "        \n",
        "    else:\n",
        "        pass\n",
        "        \n",
        "    weighting_dic[bigram] = weighting(bigram[0], bigram[1])\n",
        "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THamZfl_dz2Z",
        "colab_type": "code",
        "outputId": "e3b0b1ed-c424-49d4-eb9d-47b4ba906ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "test = random.choice(window_data)\n",
        "print(test)\n",
        "try:\n",
        "    print(X_ik[(test[0], test[1])] == X_ik[(test[1], test[0])])     #check X_ik = X_ki\n",
        "except:\n",
        "    1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('sacred', 'any')\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7DnHLQOwocg",
        "colab_type": "text"
      },
      "source": [
        "# **Prepare train data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-yG8b_iwtOt",
        "colab_type": "code",
        "outputId": "84549bc7-61f8-4037-9424-b11255096606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "u_p = [] # center vec\n",
        "v_p = [] # context vec\n",
        "co_p = [] # log(x_ij)\n",
        "weight_p = [] # f(x_ij)\n",
        "\n",
        "for pair in window_data: \n",
        "    u_p.append(prepare_word(pair[0], word2index).view(1, -1))\n",
        "    v_p.append(prepare_word(pair[1], word2index).view(1, -1))\n",
        "    \n",
        "    try:\n",
        "        cooc = X_ik[pair]\n",
        "    except:\n",
        "        cooc = 1\n",
        "\n",
        "    co_p.append(torch.log(Variable(FloatTensor([cooc]))).view(1, -1))\n",
        "    weight_p.append(Variable(FloatTensor([weighting_dic[pair]])).view(1, -1))\n",
        "\n",
        "                          \n",
        "train_data = list(zip(u_p, v_p, co_p, weight_p))\n",
        "del u_p\n",
        "del v_p\n",
        "del co_p\n",
        "del weight_p\n",
        "print(train_data[0]) # tuple (center vec i, context vec j log(x_ij), weight f(w_ij))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[1394]]), tensor([[134]]), tensor([[0.6931]]), tensor([[0.0532]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXcS4npmz1YT",
        "colab_type": "text"
      },
      "source": [
        "# **Modeling**\n",
        "\n",
        "![대체 텍스트](https://github.com/DSKSD/DeepNLP-models-Pytorch/raw/7fec64d72615933e8f4ea499c2dbaa42508f4017/images/03.glove-objective.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiuUgUNR0CCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GloVe(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size,projection_dim):\n",
        "        super(GloVe,self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, projection_dim) # center embedding\n",
        "        self.embedding_u = nn.Embedding(vocab_size, projection_dim) # out embedding\n",
        "        \n",
        "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
        "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
        "        \n",
        "        initrange = (2.0 / (vocab_size + projection_dim))**0.5 # Xavier init\n",
        "        self.embedding_v.weight.data.uniform_(-initrange, initrange) # init\n",
        "        self.embedding_u.weight.data.uniform_(-initrange, initrange) # init\n",
        "        self.v_bias.weight.data.uniform_(-initrange, initrange) # init\n",
        "        self.u_bias.weight.data.uniform_(-initrange, initrange) # init\n",
        "        \n",
        "    def forward(self, center_words, target_words, coocs, weights):\n",
        "        center_embeds = self.embedding_v(center_words) # B x 1 x D\n",
        "        target_embeds = self.embedding_u(target_words) # B x 1 x D\n",
        "        \n",
        "        center_bias = self.v_bias(center_words).squeeze(1)\n",
        "        target_bias = self.u_bias(target_words).squeeze(1)\n",
        "        \n",
        "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2) # Bx1\n",
        "        \n",
        "        loss = weights*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
        "        \n",
        "        return torch.sum(loss)\n",
        "    \n",
        "    def prediction(self, inputs):\n",
        "        v_embeds = self.embedding_v(inputs) # B x 1 x D\n",
        "        u_embeds = self.embedding_u(inputs) # B x 1 x D\n",
        "                \n",
        "        return v_embeds+u_embeds # final embed\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD-RgBgO1iCf",
        "colab_type": "text"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi4Vn1y81kRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_SIZE = 50\n",
        "BATCH_SIZE = 256\n",
        "EPOCH = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q8MpqZX2DQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = []\n",
        "model = GloVe(len(word2index), EMBEDDING_SIZE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtHG8eJA-bUr",
        "colab_type": "code",
        "outputId": "075e33c5-b708-4b55-e315-ea41e909ef1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "for epoch in range(EPOCH):\n",
        "    for i,batch in enumerate(getBatch(BATCH_SIZE, train_data)):\n",
        "        \n",
        "        inputs, targets, coocs, weights = zip(*batch)\n",
        "        \n",
        "        inputs = torch.cat(inputs) # B x 1\n",
        "        targets = torch.cat(targets) # B x 1\n",
        "        coocs = torch.cat(coocs)\n",
        "        weights = torch.cat(weights)\n",
        "        model.zero_grad()\n",
        "\n",
        "        loss = model(inputs, targets, coocs, weights)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #print(loss.data.tolist())\n",
        "\n",
        "        losses.append(loss.data.tolist())\n",
        "        #losses.append(loss.data.tolist()[0])\n",
        "    if epoch % 10 == 0:\n",
        "        print(\"Epoch : %d, mean_loss : %.02f\" % (epoch, np.mean(losses)))\n",
        "        losses = []"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0, mean_loss : 228.11\n",
            "Epoch : 10, mean_loss : 2.21\n",
            "Epoch : 20, mean_loss : 0.50\n",
            "Epoch : 30, mean_loss : 0.12\n",
            "Epoch : 40, mean_loss : 0.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOdn3U4A_I6s",
        "colab_type": "text"
      },
      "source": [
        "# **Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GqPL2he_LMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_similarity(target, vocab):\n",
        "    target_V = model.prediction(prepare_word(target, word2index))\n",
        "    similarities = []\n",
        "    for i in range(len(vocab)):\n",
        "        if vocab[i] == target: \n",
        "            continue\n",
        "            \n",
        "        vector = model.prediction(prepare_word(list(vocab)[i], word2index))\n",
        "        \n",
        "        cosine_sim = F.cosine_similarity(target_V, vector).data.tolist()[0] \n",
        "        similarities.append([vocab[i], cosine_sim])\n",
        "    return sorted(similarities, key=lambda x: x[1], reverse=True)[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmjCpY_N_q2a",
        "colab_type": "code",
        "outputId": "ae5cf1e4-332d-41c0-e49b-c08ddd69c067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "test = random.choice(list(vocab))\n",
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'since'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx7xm6tE_sez",
        "colab_type": "code",
        "outputId": "d2d0f135-e632-46b4-f080-a35008e9293b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "word_similarity(test, vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['learned', 0.677182674407959],\n",
              " ['hosmannus', 0.6526056528091431],\n",
              " ['doubt', 0.6380100846290588],\n",
              " ['justly', 0.5834043622016907],\n",
              " ['work', 0.5606750249862671],\n",
              " ['lazarus', 0.5067567825317383],\n",
              " ['hazy', 0.5046504735946655],\n",
              " ['measure', 0.47750324010849],\n",
              " ['insular', 0.4746555685997009],\n",
              " ['head', 0.4561583995819092]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    }
  ]
}