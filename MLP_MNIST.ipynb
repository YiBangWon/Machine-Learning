{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/callee2006/MachineLearning/blob/master/MLP_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7zsPERtr0LC",
        "colab_type": "text"
      },
      "source": [
        "# Multi-Layer Perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iL5KH63r0LE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If pytorch is not installed, uncommand and run the following line to install pytorch\n",
        "#!pip install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbUmP-VGVvcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoPiqjikr0LT",
        "colab_type": "text"
      },
      "source": [
        "**numpy**는 다차원 배열 및 벡터/ 행렬 기본 연산\n",
        "python으로 data science를 할 때 가장 기본이 되는 라이브러리 중 하나."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjpK8daar0LK",
        "colab_type": "code",
        "outputId": "ccc80c06-bed3-41f3-a0d7-2c3c40a1c8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torchvision            \n",
        "import torch.nn as nn\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhNkRvYkr0LN",
        "colab_type": "text"
      },
      "source": [
        "**torch**: pytorch package\n",
        "\n",
        "**torch.nn**: 신경망 모델에 Class들을 포함\n",
        "\n",
        "**torchvision**은 computer vision에 많이 사용되는 dataset, model, transform을 포함 (https://pytorch.org/docs/stable/torchvision/index.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntWD5II587og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgsGVrkrAEPD",
        "colab_type": "text"
      },
      "source": [
        "Data Loader: 데이터 로드를 위한 패키지 (Dataset + Sampler + Iterator)\n",
        "> * Dataset is an abstract class representing a dataset \n",
        "> * Sampler provides a way to iterate over indices of dataset elements\n",
        "> * Iterator: an object representing a stream of data. Repeated calls to the iterator’s next() method return successive items in the stream.\n",
        "\n",
        "See https://pytorch.org/docs/stable/data.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tUvuvvPr0LO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odn-STAQAmKq",
        "colab_type": "text"
      },
      "source": [
        "**dataset**: MNIST, fashion MNIST, COCO, LSUN, CIFAR, etc.\n",
        "\n",
        "**transforms**: algorithms for preprocessing or data augmentation\n",
        "\n",
        "See https://pytorch.org/docs/stable/torchvision/index.html to know datasets and transforms in torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtKXCay2kN5Z",
        "colab_type": "text"
      },
      "source": [
        "# Using (deep) neural networks with python\n",
        "\n",
        "\n",
        "1. Define a network model\n",
        "\n",
        "2. Prepare data\n",
        "\n",
        "3. Train the model\n",
        "\n",
        "4. Use or evalute the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCc7O8M5r0LT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "#import matplotlib\n",
        "\n",
        "from matplotlib.pyplot import imshow, imsave"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgaevoCUr0LW",
        "colab_type": "text"
      },
      "source": [
        "**matplotlib**: python visualization library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYk9uq_Br0LW",
        "colab_type": "code",
        "outputId": "c6bd196b-aaf0-427b-b7c3-e9b019a7eb28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "MODEL_NAME = 'MLP'\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"MODEL_NAME = {}, DEVICE = {}\".format(MODEL_NAME, DEVICE))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL_NAME = MLP, DEVICE = cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OivGl_-tiJhY",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhUqWS9-r0La",
        "colab_type": "text"
      },
      "source": [
        "GPU가 있다면 GPU를 통해 학습을 가속화하고, 없으면 CPU로 학습하기 위해 device를 정해준다.\n",
        "\n",
        "**torch.cuda.is_avaliable()**은 GPU가 사용가능한지를 판단하는 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ljFCGEIXfCy",
        "colab_type": "text"
      },
      "source": [
        "## Defining a Neural Network model using pytorch\n",
        "\n",
        "1. Define a neural net model\n",
        "\n",
        "> * Define a model class inheriting **nn.module**\n",
        "\n",
        ">> nn.module is the base class of all layers/operators\n",
        "\n",
        ">* Define **\\_\\_init\\_\\_** function (constructor)\n",
        "\n",
        ">>  Create layers and operators\n",
        "\n",
        ">* Define **forward** function (forward propagation)\n",
        "\n",
        ">> Define how to compute the output from the input\n",
        "\n",
        "> Example\n",
        "\n",
        "```\n",
        "    class Model(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Model, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
        "            self.conv2 = nn.Conv2d(20, 20, 5)           \n",
        "                   \n",
        "        def forward(self, x):\n",
        "            x = F.relu(self.conv1(x))\n",
        "            return F.relu(self.conv2(x))\n",
        "```            \n",
        "\n",
        "\n",
        "> Note! You don't need to backpropagation procedure, because pytorch provides **autograd**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbpvoKXzr0Lb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HelloMLP(nn.Module):\n",
        "    def __init__(self, input_size=784, num_classes=10):\n",
        "        super(HelloMLP, self).__init__()\n",
        "        self.mlp = nn.Sequential(             # a sequential container\n",
        "            # 1st layer\n",
        "            nn.Linear(input_size, 64),        # matrix multiplication (fully connected layer)            \n",
        "            nn.ReLU(),                        # activation function (nn.ReLU(), nn.Tanh(), nn.Sigmoid(), etc.)\n",
        "            \n",
        "            # 2nd layer\n",
        "            nn.Linear(64, 64),                # matrix multiplication (fully connected layer)\n",
        "            nn.ReLU(),                        # activation function\n",
        "            \n",
        "            # 3rd (output) layer\n",
        "            nn.Linear(64, num_classes),\n",
        "            # nn.Softmax(),                   # not necessary because CrossEntopyLoss class includes Softmax\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        y_ = x.view(x.size(0), -1)            # Reshape input tensor (N, 28, 28) --> (N, 784)\n",
        "        y_ = self.mlp(y_)                     # compute \n",
        "        return y_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfM4wnwdr0Le",
        "colab_type": "text"
      },
      "source": [
        "**nn.Sequential()**: a sequential container.\n",
        "\n",
        "* Example of using Sequential\n",
        "\n",
        "~~~~\n",
        "  model = nn.Sequential(\n",
        "    nn.Conv2d(1,20,5),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(20,64,5),\n",
        "    nn.ReLU()\n",
        "    )\n",
        "~~~~\n",
        "* Example of using Sequential with OrderedDict\n",
        "\n",
        "~~~~\n",
        "  model = nn.Sequential(OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1,20,5)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('conv2', nn.Conv2d(20,64,5)),\n",
        "    ('relu2', nn.ReLU())\n",
        "    ]))\n",
        "~~~~\n",
        "\n",
        "**nn.ModuleList()**: a list-like container class \n",
        "\n",
        "* Example of using ModuleList\n",
        "\n",
        "~~~~\n",
        "  class MyModule(nn.Module):\n",
        "      def __init__(self):\n",
        "          super(MyModule, self).__init__()\n",
        "          self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n",
        "            \n",
        "      def forward(self, x):\n",
        "          # ModuleList can act as an iterable, or be indexed using ints\n",
        "          for i, l in enumerate(self.linears):\n",
        "               x = self.linears[i // 2](x) + l(x)\n",
        "          return x\n",
        "                 \n",
        "~~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyP-DP1Sr0Lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = HelloMLP().to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyyU-712c1Np",
        "colab_type": "text"
      },
      "source": [
        "Moves and/or casts the parameters and buffers. (CPU or GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9-QvNvbksQj",
        "colab_type": "text"
      },
      "source": [
        "## Loading and preprocessing data\n",
        "\n",
        "1. Define transform\n",
        "\n",
        "1. Specify source of the data (specify filepath and transform)\n",
        "\n",
        "1. Create DataLoader object (specify data source, batch_size, etc.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Glhmh_OHlBMY",
        "colab_type": "text"
      },
      "source": [
        "Transform of input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq2EYzdBr0Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),                               # image to tensor\n",
        "     transforms.Normalize(mean=(0.1307,), std=(0.3081,))  # normalize to \"(x-mean)/std\"\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hE6ydS3r0Lm",
        "colab_type": "text"
      },
      "source": [
        "**transforms**: torchvision에서 제공하는 transform 함수들이 있는 패키지.\n",
        "\n",
        "**ToTensor**: numpy array를 torch tensor로 변환.\n",
        "\n",
        "**Normalize**: 정규화 함수 output[channel] = (input[channel] - mean[channel]) / std[channel]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buibF906r0Lm",
        "colab_type": "code",
        "outputId": "102ec230-feec-40f0-bf09-7ef637af836b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "mnist_train = datasets.MNIST(root='../data/', train=True, transform=transform, download=True)\n",
        "mnist_test = datasets.MNIST(root='../data/', train=False, transform=transform, download=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 9027100.44it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 135279.09it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2241196.45it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 51606.08it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlNB2l0Ii4Wp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "601b2d8b-dd14-42ce-8f0a-868dbc854642"
      },
      "source": [
        "!ls -al ../data/MNIST/raw"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 53680\n",
            "drwxr-xr-x 2 root root     4096 Jun 11 02:43 .\n",
            "drwxr-xr-x 4 root root     4096 Jun 11 02:43 ..\n",
            "-rw-r--r-- 1 root root  7840016 Jun 11 02:43 t10k-images-idx3-ubyte\n",
            "-rw-r--r-- 1 root root    10008 Jun 11 02:43 t10k-labels-idx1-ubyte\n",
            "-rw-r--r-- 1 root root 47040016 Jun 11 02:43 train-images-idx3-ubyte\n",
            "-rw-r--r-- 1 root root    60008 Jun 11 02:43 train-labels-idx1-ubyte\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CYIJISLji-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "773a39fe-51fc-4dc2-8be4-8b17e596c356"
      },
      "source": [
        "type(mnist_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.MNIST"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnSaYaMJkK2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "4efbe6f0-52d5-47bc-e469-2a061a793956"
      },
      "source": [
        "#import inspect\n",
        "#inspect.getmro(torchvision.datasets.mnist.MNIST)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torchvision.datasets.mnist.MNIST,\n",
              " torchvision.datasets.vision.VisionDataset,\n",
              " torch.utils.data.dataset.Dataset,\n",
              " object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYL_NEavr0Lo",
        "colab_type": "text"
      },
      "source": [
        "**datasets**에는 여러 데이터들에 대해 다운로드하고 처리하는 클래스가 내장되어 있음. [참고](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
        "\n",
        "root 폴더에 없을 시에 download하고, 앞서 정의한 transform에 따라 전처리 된 데이터를 return함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGbeeCkCr0Lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_n0AFCmr0Lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(dataset=mnist_test, batch_size=100, shuffle=False, drop_last=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR9GEof0r0Ls",
        "colab_type": "text"
      },
      "source": [
        "**DataLoader**는 pytorch에서 학습 시에 데이터를 배치 사이즈만큼씩 효율적으로 불러오도록 돕는 클래스. 잘 사용할수록 GPU의 사용률이 올라간다.\n",
        "\n",
        "**shuffle**: every epochs 마다 데이터의 순서를 랜덤하게 섞는다.\n",
        "\n",
        "**drop_last**: 데이터의 개수가 배치 사이즈로 나눠떨어지지 않는 경우, 마지막 배치를 버린다. 주로 학습시에만 사용."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH-t5coUmuOM",
        "colab_type": "text"
      },
      "source": [
        "## Training neural network model\n",
        "\n",
        "\n",
        " Typical training procedure\n",
        "```\n",
        "for epoch in range(max_epoch): \n",
        "    for input, target in dataset:     # retrieve input data and target labels\n",
        "        optimizer.zero_grad()           # reset gradient\n",
        "        output = model(input)           # forward propagation\n",
        "        loss = loss_fn(output, target)  # get loss value\n",
        "        loss.backward()                 # back-propagation (compute gradient)\n",
        "        optimizer.step()                # update parameters with gradient\n",
        "        \n",
        "        # Recommendation: periodically print log message including current step, loss, accuracy, etc.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRw6ytc9DZCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# utility function to measure time\n",
        "import time\n",
        "import math\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEt4xYD4r0Lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# set optimizer\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waSS2hrKr0Lv",
        "colab_type": "text"
      },
      "source": [
        "**nn.CrossEntropyLoss**: Cross entropy를 계산하는 Loss. softmax가 내부적으로 수행된다.\n",
        "\n",
        "**optim.Adam**: optim에는 여러 optimizer가 있고, Adam Optimizer는 대표적으로 많이 사용된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4lF0ODwr0Lz",
        "colab_type": "text"
      },
      "source": [
        "### Training procedure\n",
        "\n",
        "첫번째 for문: 원하는 epoch만큼 반복\n",
        "\n",
        "두번째 for문: training datset에서 배치 사이즈 만큼씩 모두 샘플링 될 때까지 반복.\n",
        "\n",
        "**Line 2**: MNIST dataset은 DataLoader를 통해 image와 label을 return.\n",
        "\n",
        "**Line 4**: 각각 Device에 올린다 (GPU or CPU)\n",
        "\n",
        "**Line 5**: 모델에 이미지를 넣고 forward propagation 한다.\n",
        "\n",
        "**Line 7**: 결과값 y_hat과 실제 정답 y에 대한 loss를 계산한다.\n",
        "\n",
        "**zero_grad (Line 9)**: 모델의 gradient를 0으로 초기화한다.\n",
        "\n",
        "**backward (Line 10)**: loss를 계산하는 것까지 연결되어있는 graph를 따라 gradient를 계산한다.\n",
        "\n",
        "**step (Line 11)**: 계산된 gradient를 모두 parameter에 적용한다.\n",
        "\n",
        "**eval (Line 17)**: 모델을 evaluation mode로 바꿔준다 (dropout 조정, Batch normalization 조정 등)\n",
        "\n",
        "**torch.no_grad (Line 19)**: gradient를 계산하기 위해 추적하는 수고를 하지 않음\n",
        "\n",
        "**torch.max (Line 24)**: max value와 indices(즉, argmax)를 return.\n",
        "\n",
        "**train (Line 29)**: evaluation mode였던 모델을 train mode로 전환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjKZyJhvMibz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reset loss history\n",
        "all_losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-KAxJESir0L0",
        "colab_type": "code",
        "outputId": "7bc6cd55-2c2e-4f84-ad68-c1e9c19a3081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "max_epoch = 5        # maximum number of epochs\n",
        "step = 0             # initialize step counter variable\n",
        "\n",
        "plot_every = 200\n",
        "total_loss = 0 # Reset every plot_every iters\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
        "\n",
        "        y_hat = model(x)            # forward propagation, y_hat.shape = (N, 10) \n",
        "       \n",
        "        loss = loss_fn(y_hat, y)    # computing loss\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        optim.zero_grad()           # reset gradient\n",
        "        loss.backward()             # back-propagation (compute gradient)\n",
        "        optim.step()                # update parameters with gradient\n",
        "        \n",
        "        # periodically print loss\n",
        "        if step % 500 == 0:\n",
        "            print('Epoch({}): {}/{}, Step: {}, Loss: {}'.format(timeSince(start), epoch, max_epoch, step, loss.item()))\n",
        "        \n",
        "        if (step + 1) % plot_every == 0:\n",
        "            all_losses.append(total_loss / plot_every)\n",
        "            total_loss = 0\n",
        "        \n",
        "        # periodically evalute model on test data\n",
        "        if step % 1000 == 0:\n",
        "            model.eval()\n",
        "            acc = 0.\n",
        "            with torch.no_grad():   # disable autograd\n",
        "                for idx, (images, labels) in enumerate(test_loader):\n",
        "                    x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
        "                    y_hat = model(x) # (N, 10)\n",
        "                    loss = loss_fn(y_hat, y)\n",
        "                    _, indices = torch.max(y_hat, dim=-1)     # find maxmum along the last axis (argmax of each row)\n",
        "                                                              # ex) max_value, max_idx = torch.max(input, dim)\n",
        "                    acc += torch.sum(indices == y).item()     # count correctly classified samples\n",
        "                                                              # torch.sum() returns Tensor. Tensor.item() converts it to a value\n",
        "            print('*'*20, 'Test', '*'*20)\n",
        "            print('Step: {}, Loss: {}, test accuracy: {} %'.format(step, loss.item(), acc/len(mnist_test)*100))\n",
        "            print('*'*46)\n",
        "            model.train()           # turn to train mode (enable autograd)\n",
        "        step += 1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch(0m 0s): 0/5, Step: 0, Loss: 2.324125051498413\n",
            "******************** Test ********************\n",
            "Step: 0, Loss: 2.270766019821167, test accuracy: 10.09 %\n",
            "**********************************************\n",
            "Epoch(0m 7s): 0/5, Step: 500, Loss: 0.16153007745742798\n",
            "Epoch(0m 12s): 1/5, Step: 1000, Loss: 0.15336540341377258\n",
            "******************** Test ********************\n",
            "Step: 1000, Loss: 0.22818508744239807, test accuracy: 95.67999999999999 %\n",
            "**********************************************\n",
            "Epoch(0m 19s): 1/5, Step: 1500, Loss: 0.11588713526725769\n",
            "Epoch(0m 25s): 2/5, Step: 2000, Loss: 0.34051281213760376\n",
            "******************** Test ********************\n",
            "Step: 2000, Loss: 0.1340450644493103, test accuracy: 96.81 %\n",
            "**********************************************\n",
            "Epoch(0m 32s): 2/5, Step: 2500, Loss: 0.03970238193869591\n",
            "Epoch(0m 37s): 3/5, Step: 3000, Loss: 0.085543692111969\n",
            "******************** Test ********************\n",
            "Step: 3000, Loss: 0.0927138403058052, test accuracy: 96.54 %\n",
            "**********************************************\n",
            "Epoch(0m 44s): 3/5, Step: 3500, Loss: 0.16477864980697632\n",
            "Epoch(0m 50s): 4/5, Step: 4000, Loss: 0.01373327523469925\n",
            "******************** Test ********************\n",
            "Step: 4000, Loss: 0.048658180981874466, test accuracy: 97.11999999999999 %\n",
            "**********************************************\n",
            "Epoch(0m 57s): 4/5, Step: 4500, Loss: 0.06157703325152397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DSxYhBXMldi",
        "colab_type": "code",
        "outputId": "c9f3fe97-8299-4ff8-fab4-48702a8bbce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbfce60ec88>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4S4i4kEKdxERD/r/fnR1w203IL0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta_UwyT1r0L6",
        "colab_type": "text"
      },
      "source": [
        "## Test and Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AwZsqeJr0L6",
        "colab_type": "code",
        "outputId": "7ce1df2a-505d-4c4b-9996-ace1cdcb4e7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Test\n",
        "model.eval()\n",
        "acc = 0.\n",
        "with torch.no_grad():\n",
        "    for idx, (images, labels) in enumerate(test_loader):\n",
        "        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
        "        y_hat = model(x) # (N, 10)\n",
        "        loss = loss_fn(y_hat, y)\n",
        "        _, indices = torch.max(y_hat, dim=-1)\n",
        "        acc += torch.sum(indices == y).item()\n",
        "print('*'*20, 'Test', '*'*20)\n",
        "print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(mnist_test)*100))\n",
        "print('*'*46)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************** Test ********************\n",
            "Step: 4685, Loss: 0.09035192430019379, Accuracy: 97.05 %\n",
            "**********************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFoQkM7Mr0L8",
        "colab_type": "code",
        "outputId": "37b215ee-3c6c-4af8-9973-9a5d75e8e458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "idx = 1415 # 0 to 9999\n",
        "img, y = mnist_test[idx]\n",
        "img.shape, y"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzrcr3vcr0L-",
        "colab_type": "code",
        "outputId": "47ea6eb7-1c0f-4d35-cdc0-a2b5c70e6008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "imshow(img[0], cmap='gray')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbfce4a5c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFOUHkqL8QFKUH0jq/wCvVd/91Zx1TwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1qgio9Rr0MC",
        "colab_type": "code",
        "outputId": "e93cdb28-d6d5-4c7a-ddbd-e05b0cc7e221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample = img.unsqueeze(dim=0).to(DEVICE)     # (1, 28, 28) -> (1, 1, 28, 28)\n",
        "out = model(sample).cpu()\n",
        "_, idx = out.max(dim=-1)\n",
        "print(\"prediction = \", idx.item())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction =  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cR6hl9hr0MF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save parameters, if necessary.\n",
        "torch.save(model.state_dict(), 'model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JLxD2e5tSh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}