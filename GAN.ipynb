{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/callee2006/MachineLearning/blob/master/Generative%20Adversarial%20Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7cFO8VuKr16",
        "colab_type": "text"
      },
      "source": [
        "# Implementation of Vanilla GANs model\n",
        "Reference: https://arxiv.org/pdf/1406.2661.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2TQr5qBKr18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the comment below only when using Google Colab\n",
        "# !pip install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_C-4VbXKr1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4so3lTmqKr2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIQZBMekKr2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import os, sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UJYgSALKr2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.pyplot import imshow, imsave\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxrxlkiiKr2G",
        "colab_type": "code",
        "outputId": "2886f0bb-fd62-4b33-bb7a-c62ba8f09bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "MODEL_NAME = 'GAN'\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"DEVICE =\",DEVICE)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEVICE = cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHLsegE6Kr2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# G: generator\n",
        "def get_sample_image(G, n_noise):\n",
        "    \"\"\"\n",
        "        synthesize samples from random noise\n",
        "    \"\"\"\n",
        "    z = torch.randn(100, n_noise).to(DEVICE)     # generate 100 random noise vectors\n",
        "    y_hat = G(z).view(100, 28, 28) # (100, 28, 28)\n",
        "    result = y_hat.cpu().data.numpy()\n",
        "    img = np.zeros([280, 280])        # 10x10 grid to tile 100 images on \n",
        "    for j in range(10):\n",
        "        img[j*28:(j+1)*28] = np.concatenate([x for x in result[j*10:(j+1)*10]], axis=-1)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtTRuccjKr2J",
        "colab_type": "text"
      },
      "source": [
        "**get_sample_image**: GAN 모델 학습 후에 Generator가 이미지를 잘 만드는지 확인하기 위한 함수\n",
        "\n",
        "**Line 5**: Generator의 input으로 사용될 noise를 배치 사이즈만큼 sampling 한다.\n",
        "\n",
        "**Line 6**: Generator의 output을 이미지 형태로 reshape한다.\n",
        "\n",
        "**Line 7**: gpu에 있는 데이터를 cpu로 가져오고 graph와 관계없이 데이터 자체에 대해서 numpy로 변환한다.\n",
        "\n",
        "**Line 8**: 시각화를 위해 저장할 배열 선언\n",
        "\n",
        "**Line 9-10**: 만들어낸 이미지 100장에 대해서 시각화하기 위해 (8)에서 선언한 배열에 반복적으로 부분 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_m-0GbDKr2K",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/callee2006/pytorch-practice/blob/master/assets/GAN.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxwPYqTFKr2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "        Simple Discriminator w/ MLP\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=784, num_classes=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, num_classes),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        y_ = x.view(x.size(0), -1)\n",
        "        y_ = self.layer(y_)\n",
        "        return y_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRJxzVrYKr2M",
        "colab_type": "text"
      },
      "source": [
        "**Discriminator**: GAN의 Discriminator model architecture 정의. Fully-connected layer 3개로 구성. 마지막은 확률로 나타내기 위해 sigmoid 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ab_cCLvKr2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "        Simple Generator w/ MLP\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=100, num_classes=784):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, num_classes),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        y_ = self.layer(x)\n",
        "        y_ = y_.view(x.size(0), 1, 28, 28)\n",
        "        return y_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PnT3Dp0Kr2O",
        "colab_type": "text"
      },
      "source": [
        "**Generator**: 일반적으로 Generator는 Discriminator보다 학습하기 어려우므로 더 깊게 FC layer 5개로 구성."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUwWx_QeKr2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dimension of noise vector\n",
        "n_noise = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNd1_mBUKr2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D = Discriminator().to(DEVICE)\n",
        "G = Generator(n_noise).to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fUu_RjDKr2U",
        "colab_type": "text"
      },
      "source": [
        "각각 모델을 메모리에 올리는 작업"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG_o76a7Kr2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                #transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "                                transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
        "                                ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW26U8N2Kr2a",
        "colab_type": "text"
      },
      "source": [
        "**transforms** torchvision에서 제공하는 transform 함수들이 있는 패키지.\n",
        "\n",
        "**ToTensor**는 numpy array를 torch tensor로 변환.\n",
        "\n",
        "**Normalize**는 다음과 같이 계산함. input[channel] = (input[channel] - mean[channel]) / std[channel]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71g2OJRzKr2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "296de745-f217-4bbc-f6e1-09ba2fbfb07b"
      },
      "source": [
        "mnist = datasets.MNIST(root='../data/', train=True, transform=transform, download=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 9271069.17it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 143204.96it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2251986.41it/s]                            \n",
            "8192it [00:00, 54345.52it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UTLB2vbKr2e",
        "colab_type": "text"
      },
      "source": [
        "GAN에서는 noise sample로부터 새로운 이미지를 만들어내는 작업이기 때문에 따로 test set을 불러올 필요가 없음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyq1l4XnKr2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wTnXfUKKr2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader = DataLoader(dataset=mnist, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKw0DIefKr2k",
        "colab_type": "text"
      },
      "source": [
        "**DataLoader**는 pytorch에서 학습 시에 데이터를 배치 사이즈만큼씩 효율적으로 불러오도록 돕는 클래스. 잘 사용할수록 GPU의 사용률이 올라간다.\n",
        "\n",
        "**shuffle**: every epochs 마다 데이터의 순서를 랜덤하게 섞는다.\n",
        "\n",
        "**drop_last**: 데이터의 개수가 배치 사이즈로 나눠떨어지지 않는 경우, 마지막 배치를 버린다. 주로 학습시에만 사용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r94AbEHEKr2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "D_opt = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "G_opt = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EamQvm0gKr2n",
        "colab_type": "text"
      },
      "source": [
        "**GAN objective**\n",
        "\n",
        "$$\\min_G \\max_D V(D,G) = \\mathbb{E}_{x\\sim p_{data}~(x)}[log D(x)] + \\mathbb{E}_{z\\sim p_x(z)}[log(1-D(G(z)))]$$\n",
        "\n",
        "**nn.BCELoss**: Binary Cross Entropy\n",
        "\n",
        "$$-{[y\\log(\\hat{y}) + (1 - y)\\log(1 - \\hat{y})]}$$\n",
        "\n",
        "**ADAM betas**: exponential decay rates for the moment estimates. (default: (0.9, 0.999))\n",
        "\n",
        "$$\\beta_1, \\beta_2 \\in [0,1)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LC42zZeKr2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_epoch = 50 # need more than 10 epochs for training generator\n",
        "step = 0\n",
        "n_critic = 1 # for training more k steps about Discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbKnzrnKKr2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_labels = torch.ones(batch_size, 1).to(DEVICE) # Discriminator Label to real\n",
        "D_fakes = torch.zeros(batch_size, 1).to(DEVICE) # Discriminator Label to fake"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccpkV-j_Kr2t",
        "colab_type": "text"
      },
      "source": [
        "Discriminator를 학습할 때는 **D(x)**는 1이 나오도록 **D(G(z))**에 대해서는 0이 나오도록,\n",
        "\n",
        "Generator를 학습할 때는 **D(G(z))**에 대해 1이 나오도록 학습하기 위해 Discriminator의 label 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJPlkSL4Kr2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('samples'):\n",
        "    os.makedirs('samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgwXALRMKr2v",
        "colab_type": "text"
      },
      "source": [
        "### Training Code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZzBqIytKr2w",
        "colab_type": "text"
      },
      "source": [
        "**line 2**: GAN에서는 MNIST의 class가 필요없으므로 image만 취함.\n",
        "\n",
        "**line 4-6**: Real sample **x**에 대해 D를 forward하고 loss 계산\n",
        "\n",
        "**line 8-10**: Fake sample **G(z)**에 대해 D를 forward하고 loss 계산\n",
        "\n",
        "**line 11**: 위 2개의 loss를 합산\n",
        "\n",
        "**line 13-15**: gradient 초기화 --> backward하면서 계산 --> parameter 업데이트\n",
        "\n",
        "**line 17**: GAN에서 gradient를 계산하는 방법은 Discriminator에 의존하므로 D를 잘 학습시키기 위해 G보다 여러번 학습시키는 테크닉. W-GAN에서 사용\n",
        "\n",
        "**line 19-25**: Generator를 위해 (8-10)과 반대로 loss를 계산하는 부분. non saturating loss **-log(D(G(z)))**를 사용하는 이유는 아래 언급함.\n",
        "\n",
        "**line 21**: 이론적으로 **log(1-D(G(z)))**를 minimize하는 것이 맞으나, 학습 초기에 G가 이미지를 잘 만들지 못해 gradient가 작은 문제로 saturate 될 수 있으므로, 그 대안으로 제시된 것이 **log(D(G(z)))**를 maximize하는 것이다.\n",
        "\n",
        "**line 30-34**: 1000 step마다 Generator가 학습이 잘 되고 있는지 샘플 이미지 만들어서 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-w-CzhlsswE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run this cell to initialize G and D\n",
        "D = Discriminator().to(DEVICE)\n",
        "G = Generator(n_noise).to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LTgCYt8WKr2w",
        "colab_type": "code",
        "outputId": "937655c8-c3f1-4b1a-dad0-9b39135e661d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "G_loss_list = []\n",
        "D_loss_list = []\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for idx, (images, _) in enumerate(data_loader):\n",
        "        # Training Discriminator\n",
        "        x = images.to(DEVICE)\n",
        "        x_outputs = D(x)\n",
        "        D_x_loss = criterion(x_outputs, D_labels)\n",
        "\n",
        "        z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
        "        z_outputs = D(G(z))\n",
        "        D_z_loss = criterion(z_outputs, D_fakes)\n",
        "        D_loss = D_x_loss + D_z_loss\n",
        "\n",
        "      \n",
        "        D.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_opt.step()\n",
        "\n",
        "        if step % n_critic == 0:\n",
        "            # Training Generator\n",
        "            z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
        "            z_outputs = D(G(z))\n",
        "            G_loss = criterion(z_outputs, D_labels)\n",
        "\n",
        "            G.zero_grad()\n",
        "            G_loss.backward()\n",
        "            G_opt.step()\n",
        "        \n",
        "        if step % 500 == 0:\n",
        "            print('Epoch: {}/{}, Step: {}, D Loss: {}, G Loss: {}'.format(epoch, max_epoch, step, D_loss.item(), G_loss.item()))\n",
        "            G_loss_list.append(G_loss.item())\n",
        "            D_loss_list.append(D_loss.item())\n",
        "        \n",
        "        if step % 1000 == 0:\n",
        "            G.eval()\n",
        "            img = get_sample_image(G, n_noise)\n",
        "            imsave('samples/{}_step{}.jpg'.format(MODEL_NAME, str(step).zfill(3)), img, cmap='gray')\n",
        "            G.train()\n",
        "        step += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/50, Step: 11000, D Loss: 0.017072804272174835, G Loss: 6.205540657043457\n",
            "Epoch: 0/50, Step: 11500, D Loss: 0.03962019830942154, G Loss: 8.96841049194336\n",
            "Epoch: 1/50, Step: 12000, D Loss: 0.009823893196880817, G Loss: 8.245841979980469\n",
            "Epoch: 1/50, Step: 12500, D Loss: 0.005063357762992382, G Loss: 7.6561479568481445\n",
            "Epoch: 2/50, Step: 13000, D Loss: 0.002445463789626956, G Loss: 7.686934947967529\n",
            "Epoch: 2/50, Step: 13500, D Loss: 0.07487145066261292, G Loss: 5.739070892333984\n",
            "Epoch: 3/50, Step: 14000, D Loss: 0.0020278235897421837, G Loss: 8.868522644042969\n",
            "Epoch: 3/50, Step: 14500, D Loss: 0.009442816488444805, G Loss: 7.217374801635742\n",
            "Epoch: 4/50, Step: 15000, D Loss: 0.005332832224667072, G Loss: 10.235108375549316\n",
            "Epoch: 4/50, Step: 15500, D Loss: 0.014287389814853668, G Loss: 6.958813667297363\n",
            "Epoch: 5/50, Step: 16000, D Loss: 0.004800278227776289, G Loss: 6.8694047927856445\n",
            "Epoch: 5/50, Step: 16500, D Loss: 0.1734900027513504, G Loss: 5.07503604888916\n",
            "Epoch: 6/50, Step: 17000, D Loss: 0.029605243355035782, G Loss: 5.75632381439209\n",
            "Epoch: 6/50, Step: 17500, D Loss: 0.01813247799873352, G Loss: 8.339418411254883\n",
            "Epoch: 7/50, Step: 18000, D Loss: 0.004233901854604483, G Loss: 7.612527847290039\n",
            "Epoch: 8/50, Step: 18500, D Loss: 0.01574200764298439, G Loss: 10.41611385345459\n",
            "Epoch: 8/50, Step: 19000, D Loss: 0.008210530504584312, G Loss: 7.209020614624023\n",
            "Epoch: 9/50, Step: 19500, D Loss: 0.0008720408077351749, G Loss: 8.900108337402344\n",
            "Epoch: 9/50, Step: 20000, D Loss: 0.009653720073401928, G Loss: 8.031501770019531\n",
            "Epoch: 10/50, Step: 20500, D Loss: 0.014342648908495903, G Loss: 5.6937713623046875\n",
            "Epoch: 10/50, Step: 21000, D Loss: 0.08091247826814651, G Loss: 7.744855880737305\n",
            "Epoch: 11/50, Step: 21500, D Loss: 0.0034302675630897284, G Loss: 8.516478538513184\n",
            "Epoch: 11/50, Step: 22000, D Loss: 0.002264691051095724, G Loss: 7.806923866271973\n",
            "Epoch: 12/50, Step: 22500, D Loss: 0.009318589232861996, G Loss: 9.593717575073242\n",
            "Epoch: 12/50, Step: 23000, D Loss: 0.030135272070765495, G Loss: 7.173668384552002\n",
            "Epoch: 13/50, Step: 23500, D Loss: 0.0029895356856286526, G Loss: 8.691886901855469\n",
            "Epoch: 13/50, Step: 24000, D Loss: 0.007704799063503742, G Loss: 7.48193359375\n",
            "Epoch: 14/50, Step: 24500, D Loss: 0.003973798826336861, G Loss: 7.132073879241943\n",
            "Epoch: 14/50, Step: 25000, D Loss: 0.003595698159188032, G Loss: 6.773451805114746\n",
            "Epoch: 15/50, Step: 25500, D Loss: 0.0008625903865322471, G Loss: 9.139907836914062\n",
            "Epoch: 16/50, Step: 26000, D Loss: 0.002710268134251237, G Loss: 8.221826553344727\n",
            "Epoch: 16/50, Step: 26500, D Loss: 0.02643599361181259, G Loss: 21.747425079345703\n",
            "Epoch: 17/50, Step: 27000, D Loss: 0.005619286559522152, G Loss: 7.38516902923584\n",
            "Epoch: 17/50, Step: 27500, D Loss: 0.0014947939198464155, G Loss: 8.017923355102539\n",
            "Epoch: 18/50, Step: 28000, D Loss: 0.018260205164551735, G Loss: 9.57470703125\n",
            "Epoch: 18/50, Step: 28500, D Loss: 0.0028417676221579313, G Loss: 7.531101226806641\n",
            "Epoch: 19/50, Step: 29000, D Loss: 0.017717955633997917, G Loss: 11.651924133300781\n",
            "Epoch: 19/50, Step: 29500, D Loss: 0.004795431159436703, G Loss: 8.255350112915039\n",
            "Epoch: 20/50, Step: 30000, D Loss: 0.0006288132863119245, G Loss: 10.273591995239258\n",
            "Epoch: 20/50, Step: 30500, D Loss: 0.0030029569752514362, G Loss: 8.368170738220215\n",
            "Epoch: 21/50, Step: 31000, D Loss: 0.0011793775483965874, G Loss: 7.983173370361328\n",
            "Epoch: 21/50, Step: 31500, D Loss: 0.006279204972088337, G Loss: 6.6801252365112305\n",
            "Epoch: 22/50, Step: 32000, D Loss: 0.01721380278468132, G Loss: 8.927534103393555\n",
            "Epoch: 22/50, Step: 32500, D Loss: 0.00010531823500059545, G Loss: 11.091259002685547\n",
            "Epoch: 23/50, Step: 33000, D Loss: 0.0005428884760476649, G Loss: 9.457132339477539\n",
            "Epoch: 24/50, Step: 33500, D Loss: 0.026661192998290062, G Loss: 42.57115173339844\n",
            "Epoch: 24/50, Step: 34000, D Loss: 0.0012832947541028261, G Loss: 7.962080001831055\n",
            "Epoch: 25/50, Step: 34500, D Loss: 0.002940555103123188, G Loss: 8.231060028076172\n",
            "Epoch: 25/50, Step: 35000, D Loss: 0.0009441556758247316, G Loss: 9.213018417358398\n",
            "Epoch: 26/50, Step: 35500, D Loss: 0.0306414645165205, G Loss: 6.855942249298096\n",
            "Epoch: 26/50, Step: 36000, D Loss: 0.0021525942720472813, G Loss: 12.038948059082031\n",
            "Epoch: 27/50, Step: 36500, D Loss: 0.000524238683283329, G Loss: 8.796098709106445\n",
            "Epoch: 27/50, Step: 37000, D Loss: 0.014627888798713684, G Loss: 9.935175895690918\n",
            "Epoch: 28/50, Step: 37500, D Loss: 0.021666239947080612, G Loss: 7.52801513671875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdRvG-oPsIyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.ion()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(G_loss_list, label='generator')\n",
        "plt.plot(D_loss_list, label='discriminator')\n",
        "plt.xlabel('x 500 steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA1DWc2LKr2y",
        "colab_type": "text"
      },
      "source": [
        "## Visualize Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z1c8k4XKr2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generation to image\n",
        "G.eval()\n",
        "imshow(get_sample_image(G, n_noise), cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syY8Vn-_Kr21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving params.\n",
        "torch.save(D.state_dict(), 'D.pkl')\n",
        "torch.save(G.state_dict(), 'G.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6zgG3o_Kr22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
